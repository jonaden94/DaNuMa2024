{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "home_dir = os.path.expanduser('~')\n",
    "raw_data_dir = os.path.join(home_dir, 'repos/DaNuMa2024/data/raw_data')\n",
    "output_data_dir = os.path.join(home_dir, 'repos/DaNuMa2024/data/output_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will implement and train the simplest neural network architecture there is: a multilayer perceptron. You will see how it is able to solve non-linear function approximation problems. Also, you will demonstrate the advantage of validation during model training to prevent overfitting.\\\n",
    "Furthermore, the convolution layer will be introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the toy dataset we use for model training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(raw_data_dir, '3_mlp/train.csv')\n",
    "val_path = os.path.join(raw_data_dir, '3_mlp/val.csv')\n",
    "\n",
    "train_data = pd.read_csv(train_path, header=None)\n",
    "val_data = pd.read_csv(val_path, header=None)\n",
    "\n",
    "x_train = train_data.iloc[:, 0].to_numpy()\n",
    "y_train = train_data.iloc[:, 1].to_numpy()\n",
    "x_val = val_data.iloc[:, 0].to_numpy()\n",
    "y_val = val_data.iloc[:, 1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data! (It is very unusual to have a bigger validation than training set. Don't do this in practice! :P It serves demonstration purposes here to get a smoother validation loss later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the dataset that loads the x and y values as tuples.\n",
    "* The dataset is usually the point where other data types are transformed to tensors.\n",
    "* Remember that a dataset must have a constructor as it is an object (\\_\\_init\\_\\_) as well as a \\_\\_len\\_\\_ and \\_\\_getitem\\_\\_ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### dataset\n",
    "class MLPDataset(Dataset):\n",
    "    ######### YOUR CODE HERE:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the MLP. \n",
    "* Remember that a model must have a constructor as it is an object (\\_\\_init\\_\\_) as well as a forward method that calculates the model output.\n",
    "* The layer sizes should be [1, 32, 64, 128, 256, 128, 64, 32, 1]. \n",
    "* The 1 at the beginning and end denote the input and output size of the model, which is one-dimensional in our case. \n",
    "* The numbers in-between denote the hidden layer sizes. So the network has 7 hidden layers.\n",
    "* Bonus: If you want to define the network more elegantly, you can also pass the layer sizes to the constructor and define the network dynamically based on what layer sizes you provide as an argument to the network. You can make use of a loop together with a list and nn.Sequential to define the layers this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### model\n",
    "\n",
    "########### elegant solution\n",
    "class MLP(nn.Module):\n",
    "    ######### YOUR CODE HERE:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a simple training loop without validation. \n",
    "* Use the mean squared error as a loss function (mse_loss) and AdamW as the optimizer. \n",
    "* Store the average loss in every epoch in a list so that you can later plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Training loop without validation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"The model is running on {device}.\")\n",
    "\n",
    "# training parameters\n",
    "epochs = 4000\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "\n",
    "# instantiate dataset and dataloader\n",
    "######### YOUR CODE HERE:\n",
    "\n",
    "# instantiate model and optimizer\n",
    "######### YOUR CODE HERE:\n",
    "\n",
    "# training loop\n",
    "all_train_losses = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    ######### YOUR CODE HERE:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the training losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the data together with the predictions \n",
    "* Hint: you can use the torch.linspace function to create a sequence of x values for which to generate model predictions for plotting.\n",
    "* What do you observe? Is the model you obtained in the last epoch a good approximation for the underlying function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop with validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent overfitting, it is often useful to also calculate the loss on a held out validation set that is not used during training from time to time. Your task is to implement this in the training loop.\n",
    "* For clearer code, implement the training of one epoch and the validation in separate functions\n",
    "* Implement a logic that saves the parameters of the model (torch.save(model.state_dict(), save_path)) whenever the validation loss decreases. This way you can later use the model with the best validation loss.\n",
    "* This time, plot both the training and validation loss curve. What do you observe?\n",
    "* Take the model with the best validation loss to make a model prediction. You can load saved parameters to a model via model.load_state_dict(torch.load(save_path)). How does the prediction look compared to the model obtained without validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, trainloader, optimizer, device):\n",
    "    ######### YOUR CODE HERE:\n",
    "    pass\n",
    "\n",
    "def validate(model, valloader, device):\n",
    "    ######### YOUR CODE HERE:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Training loop with modular definition of training and validation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"The model is running on {device}.\")\n",
    "\n",
    "# training parameters\n",
    "epochs = 4000\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "val_interval = 1\n",
    "save_path_state_dict = os.path.join(output_data_dir, '3_mlp/best_model_state_dict.pth')\n",
    "\n",
    "# instantiate dataset and dataloader (train and val this time!)\n",
    "######### YOUR CODE HERE:\n",
    "trainloader = None\n",
    "valloader = None\n",
    "\n",
    "# instantiate model and optimizer\n",
    "######### YOUR CODE HERE:\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# training loop\n",
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = train_one_epoch(model, trainloader, optimizer, device)\n",
    "    all_train_losses.append(train_loss)\n",
    "\n",
    "    if epoch % val_interval == 0:\n",
    "        val_loss = validate(model, valloader, device)\n",
    "        all_val_losses.append(val_loss)\n",
    "\n",
    "    ######### YOUR CODE HERE:\n",
    "    # Implement a logic to save the model state dict if the validation loss has decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### plot training and validation losses.\n",
    "######### YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### plot train and val data together with the model predictions from the model with the best validation loss\n",
    "######### YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of the convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a more complex model component, the so-called convolution layer. \\\n",
    "The convolution layer is an essential module when processing images with neural networks. \\\n",
    "Once again we set the bias to zero for simplicity and set all parameter values of the layer to 1. \\\n",
    "The convolution layer takes three arguments: in_channels, out_channels and kernel_size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, bias=False)\n",
    "torch.nn.init.constant_(conv_layer.weight, 1.0)\n",
    "print(conv_layer.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the convolution layer will have a shape of out_channels x in_channels x kernel_size x kernel_size (in this case 8x8x3x3). \\\n",
    "However, it is easier to think of these parameters as 8 separate \"kernels\" which each have a size of 8x3x3. \\\n",
    "When you apply the convolution layer on an input, these kernels will \"slide\" over the input and perform pairwise multiplication with the repsective part of the input. \\\n",
    "Since we initialized the weights of the kernel with all ones, the result will be the sum of the values at the respective part of the input. \\\n",
    "Also notice that the input size shrinks from 7 to 5 since no padding applied automatically. This would have to be specified as a separate argument when initializing the conv_layer. \\\n",
    "A really nice animated example of a convolution layer with the same input/output channels and kernel size can be found here: https://animatedai.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.ones(8, 7, 7)\n",
    "output = conv_layer(input)\n",
    "print(f'Shape of the output: {output.shape}')\n",
    "print(f'As expected, the output values are just the sums of the values of the respective part of the input: \\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: Feel free to explore the documentation of the conv module or build your own mini convnet! Is there an argument that prevents the shrinking of the input size?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
