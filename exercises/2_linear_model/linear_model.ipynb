{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this notebook in google colab, set colab to True else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data directory\n",
    "import os\n",
    "if colab:\n",
    "    home_dir = '/content'\n",
    "    output_data_dir = os.path.join(home_dir, 'data/output_data')\n",
    "    os.makedirs(output_data_dir, exist_ok=True)\n",
    "else:\n",
    "    exercise_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    danuma_dir = os.path.dirname(os.path.dirname(exercise_dir))\n",
    "    output_data_dir = os.path.join(danuma_dir, 'data/output_data/2_linear_model')\n",
    "    os.makedirs(output_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the full process of training a model in pytorch, including data loading and visualization of the results, using a simple linear model with dummy data as a minimal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate toy data according to simple linear model\n",
    "N = 50\n",
    "torch.manual_seed(3)\n",
    "x = torch.linspace(0, 10, N)\n",
    "y = x * 5 + torch.randn(N) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "\n",
    "ax.set_aspect(0.1)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# define torch dataset\n",
    "class LinearDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    # torch dataset must have __getitem__ method!\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    # torch dataset must have __len__ method!\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# define dataloader\n",
    "dataset = LinearDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# define model\n",
    "class LinearModel(nn.Module):\n",
    "    # initialize model parameters\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    # model must have forward method!\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# instantiate model\n",
    "model = LinearModel()\n",
    "\n",
    "# define loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# instantiate optimizer with model parameters\n",
    "optimizer = AdamW(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "epochs = 1000\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        # add batch dimension\n",
    "        x_batch = x_batch.unsqueeze(1)\n",
    "        y_batch = y_batch.unsqueeze(1)\n",
    "\n",
    "        # reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        # calculate loss and backward pass\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        # update model parameters\n",
    "        optimizer.step()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = [i for i in range(epochs)]\n",
    "plt.plot(epoch, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # when making predictions, set model to evaluation mode. Can be set to train mode again with model.train()\n",
    "with torch.no_grad(): # disable gradient calculation\n",
    "    y_pred = model(x.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)  # Optional: label for scatter points\n",
    "\n",
    "# Set the aspect ratio as specified\n",
    "ax.set_aspect(0.1)  # x:y ratio\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "# Plot the prediction line and add a label\n",
    "ax.plot(x, y_pred, c='r', label='Prediction')\n",
    "\n",
    "# Add the legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize gradual change of parameter during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the prediction the model makes after every training epoch to visualize the gradual learning of the parameter. Just run the code to get the visualization gif (takes roughly 30 seconds). You do not have to understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = LinearModel()\n",
    "\n",
    "# define loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# instantiate optimizer with model parameters\n",
    "optimizer = AdamW(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "epochs = 1000\n",
    "losses = []\n",
    "\n",
    "y_preds_after_every_epoch = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        # add batch dimension\n",
    "        x_batch = x_batch.unsqueeze(1)\n",
    "        y_batch = y_batch.unsqueeze(1)\n",
    "\n",
    "        # reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        # calculate loss and backward pass\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        # update model parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # make predictions after every epoch with current parameters\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x.unsqueeze(1))\n",
    "        y_preds_after_every_epoch.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import os\n",
    "\n",
    "y_min = 100000\n",
    "y_max = -100000\n",
    "\n",
    "# Adjust y_min and y_max to accommodate all y_pred values\n",
    "for y_preds in y_preds_after_every_epoch:\n",
    "    if y_min > y_preds.min():\n",
    "        y_min = y_preds.min()\n",
    "    if y_max < y_preds.max():\n",
    "        y_max = y_preds.max()\n",
    "\n",
    "images = []\n",
    "for i, y_pred in enumerate(tqdm(y_preds_after_every_epoch)):\n",
    "    # Create a plot for each set of y values\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(x, y)\n",
    "\n",
    "    # Line plot of the predicted values\n",
    "    ax.plot(x, y_pred, c='r', label='Prediction', linestyle='solid')\n",
    "\n",
    "    # Set the aspect ratio and labels\n",
    "    ax.set_aspect(0.1)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Set same y-limits for all plots\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "\n",
    "    # Add the legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Plot epoch number at the top left of the plot\n",
    "    ax.text(0.05, 0.95, f'Epoch: {i+1}', transform=ax.transAxes, \n",
    "            fontsize=12, verticalalignment='top', horizontalalignment='left',\n",
    "            bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))\n",
    "\n",
    "    # Save the plot to a bytes buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    \n",
    "    # Append the image to the list\n",
    "    images.append(img)\n",
    "    \n",
    "    # Close the plot to free memory\n",
    "    plt.close()\n",
    "    \n",
    "    if i == 300:  # Limit the number of frames to 300\n",
    "        break\n",
    "\n",
    "# Save the list of images as a GIF\n",
    "save_path = os.path.join(output_data_dir, 'parameter_development.gif')\n",
    "\n",
    "# Create the GIF\n",
    "images[0].save(save_path, save_all=True, append_images=images[1:], duration=50, loop=0)\n",
    "\n",
    "print(f\"GIF saved as '{save_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danuma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
